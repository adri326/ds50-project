{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://enjoymachinelearning.com/blog/finding-semantic-similarity-between-sentences-in-python/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2557a58dcbc441fb9706cd44dc84592"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3fda848dbfa4809a42cd6953aabe26f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77f49cc56e9a4b3ebe4ed3a7c0fe214a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa4e7de66c124e37bf9a42ba7bf911ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dff6248b13cf4125913211dfd3a41d50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55ab65650a6642d8900c161738c1084c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4757e04e40134ec5ac23421bf26c3fae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b29068c9bf84aa5980112c86a06fd2c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69360c58523248d6924fcc333c075c3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ae6bee49614e0684279a637a5d7320"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4553d15f00014d89ab31a2e61831dfe2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4e96f3f5bc944fab1ebd525ed03754d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c62d725f6b4e8888235e0ed2c04da0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1efa2d36c2154961a35c940e113f00b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i see quite a few positive reviews on this board, trying to revive this film from its lackluster status and starting a cult following. i see the usual ranting--\"i guess this movie is just not for the easily offended,\" \"this movie is not shakespeare,\" etc. guess what? neither was \"road trip\"! and i laughed my a** off during that movie! there\\'s a way to make a crude, tasteless comedy and deliver laughs; and there\\'s a way to...just make it crude and tasteless. \"whipped\" tries to be \"swingers\" without the wit or intelligence. it seems to have been written through the puerile eyes of a 14-year-old boy. for god\\'s sake, the characters in this movie are supposed to be white-collar, upright citizens--and they talk like some of the idiots i knew in freshman year of high school! the dialogue is laced--more like drowned--with four-letter words. you would think that people of their status would have some degree of intelligence--and a more extensive vocabulary. just watch a whit stillman film and you\\'ll see the difference. not to mention the fact that the dialogue sounds totally unrealistic and downright cartoonish. if you know any successful, white-collar businessmen who speak like the characters in this movie--please let me know and introduce me to them. their annoying sexual banter is equivalent to that of standard locker room chat among teens just arriving at puberty. there is absolutely no insight into relationships, sex or...anything!!! it\\'s just a poor excuse to showcase an array of extremely--and don\\'t take the word \"extremely\" for granted, because i mean it with all my heart--crude gags. these are gags with no substance. gags that are meant more for groans than laughs. the scene at the end between amanda peet and her girlfriends was totally un-called for and totally unconvincing. there are some movies that involve interaction among females that were written by (straight) men and play out wonderfully. this scene involves a barrage of sexual metaphors and gestures. it involves the kind of dialogue you can never imagine leaving a woman\\'s mouth. it was one of those noticeably-written-by-a-guy scenes. i wasn\\'t believing it for a second.  / /\"whipped\" is purely a sick male fantasy that\\'s as flat as it is annoying. i got (very) few laughs out of this utterly forgettable comedy, and those were probably a result of desperation. when you\\'re not laughing for a long period of time, you desperately look for humor in the most trivial things. so i wouldn\\'t mark that down as a positive.'] \n",
      "\n",
      "Length Of Data 2000\n"
     ]
    }
   ],
   "source": [
    "# comparing the two sentences using SBERT and Cosine Similarity\n",
    "\n",
    "# here's the install command\n",
    "#!pip install -U sentence-transformers\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "# load our Sentence Transformers model pre trained!!\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# as always, we will get sentences from a\n",
    "# public kaggle dataset\n",
    "# https://www.kaggle.com/datasets/columbine/imdb-dataset-sentiment-analysis-in-csv-format?resource=download\n",
    "df = pd.read_csv('../../dataset/similarity/train.csv')\n",
    "\n",
    "# while this data has lots of good info, we just need the reviews\n",
    "# let's grab 2000\n",
    "\n",
    "# in real-life, you should not clean data like this\n",
    "# since this wasn't a data cleaning tutorial I didn't want to bloat\n",
    "# the code\n",
    "\n",
    "# this is not production ready data!!\n",
    "sentences = [sentence.lower()\n",
    "             .replace('br','')\n",
    "             .replace('<',\"\")\n",
    "             .replace(\">\", \"\")\n",
    "             .replace('\\\\',\"\")\n",
    "             .replace('\\/',\"\")\n",
    "             for sentence in df.text.sample(n=2000)]\n",
    "\n",
    "\n",
    "#see a sentence, and our length\n",
    "print(sentences[5:6], f'\\n\\nLength Of Data {len(sentences)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T14:47:54.938392Z",
     "start_time": "2023-05-24T14:46:52.219001Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score : \n",
      "\n",
      "  0.4778851270675659\n",
      "\n",
      "Sentence : \n",
      "\n",
      " this movie was pure genius. john waters is illiant. it is hilarious and i am not sick of it even after seeing it about 20 times since i bought it a few months ago. the acting is great, although ricki lake could have been better. and johnny depp is magnificent. he is such a beautiful man and a very talented actor. and seeing most of johnny's movies, this is probably my favorite. i give it 9.5/10. rent it today!\n",
      "\n",
      "Score : \n",
      "\n",
      "  0.4539894759654999\n",
      "\n",
      "Sentence : \n",
      "\n",
      " i've seen this film literally over 100 times...it's absolutely jam-packed with entertainment!!! powers boothe gives a stellar performance. as a fan of actors such as william shatner (impulse, 1974) and ron liebmann (up the academy, 1981)i never thought an actor could capture the \"intensity\" like shatner and liebmann in those roles, until i saw boothe as jim jones! as far as i'm concerned, powers boothe is jim jones...this film captures his best performance!!!\n"
     ]
    }
   ],
   "source": [
    "# lets find the semantically closest sentence to a random sentence\n",
    "# that we come up with, in our dataset\n",
    "\n",
    "# i like action movies, mission impossible is one of my favorites\n",
    "our_sentence = 'I really love action movies, huge tom cruise fan!'\n",
    "\n",
    "# lets embed our sentence\n",
    "my_embedding = model.encode(our_sentence)\n",
    "\n",
    "# lets embed the corpus\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between my sentence, and each one in the corpus\n",
    "cos_sim = util.cos_sim(my_embedding, embeddings)\n",
    "\n",
    "# lets go through our array and find our best one!\n",
    "# remember, we want the highest value here (highest cosine similiarity)\n",
    "winners = []\n",
    "for arr in cos_sim:\n",
    "    for i, each_val in enumerate(arr):\n",
    "        winners.append([sentences[i],each_val])\n",
    "\n",
    "# lets get the top 2 sentences\n",
    "final_winners = sorted(winners, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "for arr in final_winners[0:2]:\n",
    "    print(f'\\nScore : \\n\\n  {arr[1]}')\n",
    "    print(f'\\nSentence : \\n\\n {arr[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T14:48:38.263897Z",
     "start_time": "2023-05-24T14:48:02.444451Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
